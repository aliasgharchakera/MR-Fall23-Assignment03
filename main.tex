\documentclass[answers]{exam}

\usepackage{amsmath, amsfonts, amssymb}
\usepackage{geometry}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{listings}
% \usepackage{subfig}
\usepackage{float}

\lstset{
    basicstyle=\ttfamily,
    columns=fullflexible,
    frame=single,
    breaklines=true,
    postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}

% Header and footer.
\pagestyle{headandfoot}
\runningheadrule
\runningfootrule
\runningheader{EE/CE 468/468 Mobile Robotics}{Homework 3}{Fall 2023}
\runningfooter{}{Page \thepage\ of \numpages}{}
\firstpageheader{}{}{}

\boxedpoints
\printanswers

\newcommand{\uvec}[1]{\boldsymbol{\hat{\textbf{#1}}}}
\newcommand\union\cup 
\newcommand\inter\cap
\newcommand\ul\underline
\newcommand\ol\overline

\title{Assignment 3\\ EE/CE 468/468 Mobile Robotics\\ Habib University -- Fall 2023}
\author{Ali Asghar Yousuf \\ Muhammad Azeem Haider }
\date{\today}

\begin{document}
\maketitle

\begin{questions}
    \question[20]
    Consider a robot that lives in a 1-D coordinate system. Its location will be denoted by \(x\), its velocity by \(\dot{x}\), and its acceleration by \(\ddot{x}\). Suppose we can only control the acceleration \(\ddot{x}\). Making use of equations of motion from school physics, write the discrete-time motion model for this system. Assume that the acceleration \(\ddot{x}\) is a sum of a commanded acceleration and a zero-mean noise term with variance \(\sigma^2\) and assume that the actual acceleration remains constant in an interval \(\Delta t\).
    \begin{parts}
        \part Find the uncertainty/covariance in the pose \((x, \dot{x})\) after one time step. Are the two correlated?
        \begin{solution}
            \textbf{Solution for Part A:}
            
            \textbf{Derivation of State Update Equations:}
            
            Given the state vector at time \( t \) as \( \mathbf{x}_t = \begin{bmatrix} x_t \\ \dot{x}_t \end{bmatrix} \), and the control input modeled as acceleration with additive Gaussian noise, \( \ddot{x}_t = u_t + \epsilon_t \) where \( \epsilon_t \sim \mathcal{N}(0, \sigma^2) \), the state update equations in discrete time are derived using classic kinematic equations:
            
            The velocity update equation:
            \[ \dot{x}_{t+1} = \dot{x}_t + (u_t + \epsilon_t) \Delta t \]
            which corresponds to the physics equation of motion \( v = u + at \) adapted for discrete time and control input with noise.
            
            The position update equation:
            \[ x_{t+1} = x_t + \dot{x}_t \Delta t + \frac{1}{2}(u_t + \epsilon_t) (\Delta t)^2 \]
            which is based on the equation \( s = ut + \frac{1}{2}at^2 \), adapted for discrete time and noisy control input.
            
            \textbf{Covariance Matrix Computation:}
            
            The covariance matrix \(\mathbf{\Sigma}_{t+1}\) of the state after one time step can be computed considering the process noise. Assuming the initial state is known exactly (\(\mathbf{\Sigma}_t = \mathbf{0}\)), the covariance matrix after one time step is given by:
            \[ \mathbf{\Sigma}_{t+1} = \mathbf{A}_t \mathbf{\Sigma}_t \mathbf{A}_t^\top + \mathbf{Q}_t \]
            where \(\mathbf{A}_t\) is the state transition matrix and \(\mathbf{Q}_t\) is the process noise covariance matrix. Given \(\mathbf{A}_t\) as
            \[ \mathbf{A}_t = \begin{bmatrix} 1 & \Delta t \\ 0 & 1 \end{bmatrix} \]
            and \(\mathbf{Q}_t\) as
            \[ \mathbf{Q}_t = \begin{bmatrix} \frac{1}{4}(\Delta t)^4 & \frac{1}{2}(\Delta t)^3 \\ \frac{1}{2}(\Delta t)^3 & (\Delta t)^2 \end{bmatrix} \sigma^2 \]
            we can compute \(\mathbf{\Sigma}_{t+1}\) as:
            \[ \mathbf{\Sigma}_{t+1} = \mathbf{Q}_t = \begin{bmatrix} \frac{1}{4}(\Delta t)^4 & \frac{1}{2}(\Delta t)^3 \\ \frac{1}{2}(\Delta t)^3 & (\Delta t)^2 \end{bmatrix} \sigma^2 \]
            
            This covariance matrix reflects the propagation of uncertainty from the process noise through the system and indicates the correlation between position and velocity after one time step.
        \end{solution}
        
        \part Suppose we control this robot with a commanded acceleration sequence \(a_1, a_2, a_3, \ldots\) for \(T\) time intervals. Will the final location \(x\) and the final velocity \(\dot{x}\) be correlated for some large value of \(T\)?
        \begin{solution}
            \textbf{Solution for Part B:}
            
            Given the discrete-time dynamical system with state vector at time step \( t \) as \( \mathbf{x}_t \) and control input as the acceleration \( u_t \) with additive Gaussian noise \( \epsilon_t \), the system can be described as:
            
            \begin{itemize}
                \item The control input noise \( \epsilon_t \) is Gaussian distributed with zero mean and variance \( \sigma^2 \), that is \( \epsilon_t \sim \mathcal{N}(0, \sigma^2) \).
                \item The system follows a linear state-space model with the state transition matrix \( \mathbf{A} \) and control input matrix \( \mathbf{B} \).
            \end{itemize}
            
            The state update equation is:
            \[ \mathbf{x}_{t+1} = \mathbf{A} \mathbf{x}_t + \mathbf{B} (u_t + \epsilon_t) \]
            where
            \[ \mathbf{A} = \begin{bmatrix} 1 & \Delta t \\ 0 & 1 \end{bmatrix}, \quad \mathbf{B} = \begin{bmatrix} \frac{1}{2} (\Delta t)^2 \\ \Delta t \end{bmatrix}, \quad \mathbf{x}_t = \begin{bmatrix} x_t \\ \dot{x}_t \end{bmatrix}. \]
            
            After \( T \) time intervals, the final state \( \mathbf{x}_T \) can be expressed as:
            \[ \mathbf{x}_T = \mathbf{A}^T \mathbf{x}_0 + \sum_{t=0}^{T-1} \mathbf{A}^{T-t-1} \mathbf{B} (u_t + \epsilon_t). \]
            
            The covariance matrix of the final state \( \mathbf{x}_T \), which encapsulates the accumulated uncertainty from the process noise, is given by:
            \[ \mathbf{\Sigma}_T = \sum_{t=0}^{T-1} \mathbf{A}^{T-t-1} \mathbf{B} \mathbf{Q} \mathbf{B}^\top (\mathbf{A}^{T-t-1})^\top, \]
            where \( \mathbf{Q} \) is the covariance matrix of the process noise \( \epsilon_t \).
            
            The non-zero off-diagonal terms of the covariance matrix \( \mathbf{\Sigma}_T \) indicate a correlation between the final location and velocity. This correlation results from the control input noise, which affects both velocity and position over time due to the system's dynamics.
        \end{solution}
                   
    \end{parts}

    \question[20]
    Suppose we have a mobile robot operating in a planar environment. Its state is its \(x\)-\(y\) location and its global heading direction \(\theta\). Suppose we know \(x\) and \(y\) with high certainty but the orientation \(\theta\) is unknown. This is reflected in our initial estimate:
    \[
    \hat{x}_0 = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}, \quad
    \Sigma_0 = \begin{bmatrix} 0.01 & 0 & 0 \\ 0 & 0.01 & 0 \\ 0 & 0 & 10000 \end{bmatrix}.
    \]
    \begin{parts}
        \part Assume that the robot moves flawlessly without any noise. We'll consider the simple case when the robot's heading is not being controlled i.e. \(\omega = 0\). Observations of the robot are made at discrete points in time and consist of the robot's distance from the origin \(d\) and the bearing \(\theta\) measured from the origin. Assume that the noise associated with these two measurements are independent. Develop a Kalman Filter that maintains an estimate of the robot’s state.
        \begin{solution}
        \end{solution}

        \part The location of the robot is a random vector. Draw 1000 samples of the initial state from a Gaussian distribution of the stated mean and covariance, propagate each initial state sample according to the motion equation and plot the samples of the \(x\)-\(y\) state only at time 1 in MATLAB. Assume that distance covered in one time step is 1.
        \begin{solution}
        \end{solution}

        \part Use the prediction step of the EKF to make a prediction about the state at time 1 and its corresponding covariance. Plot the uncertainty ellipse of a Gaussian with mean equal to \(\bar{x}_1\) and covariance \(\bar{\Sigma}_1\) on the same plot as (a) and compare and comment on the two.
        \begin{solution}
        \end{solution}

        \part Now incorporate a noisy measurement i.e. \(z = d + \epsilon\) where \(\epsilon\) is zero-mean with covariance 0.01. Again draw the uncertainty ellipse on the same plot after incorporating the measurement.
        \begin{solution}
        \end{solution}

        \part What would have been your estimate for the \(x\)-\(y\) at time 1 considering (a)? What would be your comments about the estimate provided by the EKF? What would have happened if the initial orientation were known but we were uncertain about the \(y\) coordinate?
        \begin{solution}
        \end{solution}
    \end{parts}

    \question[20]
    Suppose we live at a place where days are either sunny, cloudy, or rainy. The weather tomorrow is determined solely by the weather today (it’s a Markov Chain) and is captured by the following state transition probabilities:
    \begin{center}
    \textbf{Today's Weather} \\
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{} & \textbf{Sunny} & \textbf{Cloudy} & \textbf{Rainy} \\ \hline
    \textbf{Sunny} & 0.8 & 0.2 & 0 \\ \hline
    \textbf{Cloudy} & 0.4 & 0.4 & 0.2 \\ \hline 
    \textbf{Rainy} & 0.2 & 0.6 & 0.2 \\ \hline
    \end{tabular}
    \end{center}
    Suppose that we cannot observe the weather directly but instead rely on a sensor. Our sensor is noisy. The measurements are governed by the following measurement model:
    \begin{center}
    \textbf{Actual Weather} \\
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{} & \textbf{Sunny} & \textbf{Cloudy} & \textbf{Rainy} \\ \hline
    \textbf{Sunny} & 0.6 & 0.4 & 0 \\ \hline
    \textbf{Cloudy} & 0.3 & 0.7 & 0 \\ \hline
    \textbf{Rainy} & 0 & 0 & 1 \\ \hline
    \end{tabular}
    \end{center}
    \begin{parts}
        \part Suppose Day 1 is sunny (this is known for a fact). At days 2 through 4 the sensor measures sunny, sunny, rainy. For each of the days 2 through 4 what is the most likely weather on that day. Answer the question in two ways: one in which only the data available to the day in question is used and one in hindsight where data from future days is also available.
        
        \begin{solution}
            \textbf{Day 2 $\mid$ only data available to the day in question is used}
            \begin{align*}
                P(x_2 \mid x_1, z_2) &= \eta P(z_2 \mid x_2, x_1) P(x_2 \mid x_1) \\
                &= \eta P(z_2 \mid x_2) P(x_2 \mid x_1) \\
                &= \eta \begin{bmatrix}
                    0.6 \\
                    0.3 \\
                    0 
                \end{bmatrix} \cdot \begin{bmatrix}
                    0.8 \\
                    0.2 \\
                    0
                \end{bmatrix} \\
                &= \eta \begin{bmatrix}
                    0.48 \\
                    0.06 \\
                    0
                \end{bmatrix} \\
                &= \eta \left( 0.48 + 0.06 + 0 \right) \begin{bmatrix}
                    0.48 \\
                    0.06 \\
                    0
                \end{bmatrix} \\
                &= \frac{1}{0.54} \begin{bmatrix}
                    0.48 \\
                    0.06 \\
                    0
                \end{bmatrix} \\
                &= \begin{bmatrix}
                    8/9 \\
                    1/9 \\
                    0
                \end{bmatrix}
            \end{align*}
            Here, \(\eta = \frac{1}{0.54}\) is the normalizing constant. \\
            Therefore, the most likely weather on Day 2 is \textit{sunny} given that we are only using the data available to us.
            
            \textbf{Day 3 $\mid$ only data available to the day in question is used}
            \begin{align*}
                P(x_3 \mid x_2, z_{2:3}) &= \eta P(z_3 \mid x_3, x_1, x_2) P(x_3 \mid x_1, x_2) \\
                &= \eta P(z_3 \mid x_3) \sum_{x_2} P(x_3, x_2 \mid x_1, x_2) \\
                &= \eta P(z_3 \mid x_3) \sum_{x_2} P(x_3 \mid x_2) P(x_2 \mid x_1, x_2)
            \end{align*}
            
            \text{We know:}
            \begin{align*}
                P(x_2 \mid x_1, z_2) &= \begin{bmatrix}
                    8/9 \\
                    1/9 \\
                    0
                \end{bmatrix} \\
                P(z_3 \mid x_3) &= \begin{bmatrix}
                    0.6 \\
                    0.3 \\
                    0
                \end{bmatrix} \\
                \text{We get the following equation:} \\
                P(x_3 \mid x_2, z_{2:3}) &= \eta \begin{bmatrix}
                    0.6 \\
                    0.3 \\
                    0
                \end{bmatrix} \sum_{x_2} P(x_3 \mid x_2) \begin{bmatrix}
                    8/9 \\
                    1/9 \\
                    0
                \end{bmatrix}
            \end{align*}
            
            \text{For Sunny:}
            \begin{align*}
                0.6 \times \left[\begin{bmatrix} 0.8 & 0.4 & 0.2 \end{bmatrix} \cdot \begin{bmatrix}
                    8/9 \\
                    1/9 \\
                    0
                \end{bmatrix}\right] &= \frac{34}{75}
            \end{align*}
            
            \text{For Cloudy:}
            \begin{align*}
                0.3 \times \left[\begin{bmatrix} 0.2 & 0.4 & 0.6 \end{bmatrix} \cdot \begin{bmatrix}
                    8/9 \\
                    1/9 \\
                    0
                \end{bmatrix}\right] &= \frac{1}{15}
            \end{align*}

            \text{For Rainy:}
            \begin{align*}
                0 \times \left[\begin{bmatrix} 0 & 0.2 & 0.2 \end{bmatrix} \cdot \begin{bmatrix}
                    8/9 \\
                    1/9 \\
                    0
                \end{bmatrix}\right] &= 0
            \end{align*}
            \text{Normalizing the matrix to get the accurate probability we get;}

            Sunny $=$ 87.2\% \\
            Cloudy $=$ 12.8\% \\
            Rainy $=$ 0\% \\

            Therefore, once again the most likely weather on Day 3 is sunny given that we are only using the data available to us.

            \textbf{Day 4 $\mid$ only data available to the day in question is used}
            \begin{align*}
                P(x_4 | x_1, x_2;x_4) &= P(x_4 | x_3, x_4) \\
                P(x_4 | x_1, x_2;x_4) &= \eta P(z_4 | x_4)P(x_4 | x_3) \\
                P(x_4 | x_1, x_2;x_4) &= \begin{bmatrix}
                0 \\
                0 \\
                1
                \end{bmatrix}
            \end{align*}

            We know for sure that on the fourth day it will rain if the sensor has predicted it to rain.

            % \newpage
            \textbf{Day 2 $\mid$ where data from future days is also available}
            % \vspace{-5mm}
            \begin{align*}
                P(x_{2:4} | x_1, z_{2:4}) &= \eta P(x_{2:4} | x_1) P(z_{2:4} | x_{2:4}, x_1) \\
                &= \eta P(x_{2} | x_1) P(z_{2:4} | x_2) \\
                &= \eta P(x_{2} | x_1) P(z_{2} | x_2) \sum_{x_3} P(x_3 | x_2, z_2) P(z_{3:4} | x_2) \\
                &= \eta P(x_{2} | x_1) P(z_{2} | x_2) \sum_{x_3} P(x_3 | x_2) P(z_{3:4} | x_3, x_2) \\
                &= \eta P(x_{2} | x_1) P(z_{2} | x_2) \sum_{x_3} P(x_3 | x_2) P(z_3 | x_3) P(z_{4:3} | x_3) \\
                &= \eta P(x_{2} | x_1) P(z_{2} | x_2) \sum_{x_3} P(x_3 | x_2) P(z_3 | x_3) \sum_{x_4} P(x_4 | x_3) P(z_4 | x_4, x_3) \\
                &= \eta P(x_{2} | x_1) P(z_{2} | x_2) \sum_{x_3} P(x_3 | x_2) P(z_3 | x_3) \sum_{x_4} P(x_4 | x_3) P(z_4 | x_3) \\
                &= \eta P(x_{2} | x_1) P(z_{2} | x_2) \sum_{x_3} P(x_3 | x_2) P(z_3 | x_3) \sum_{x_4} P(x_4 | x_3) P(z_4 | x_4) \\ 
            \end{align*}
            % \vspace{-10mm}
            \begin{align*}    
                P(z_4 | x_4) &= \begin{bmatrix}
                0 \\
                0 \\
                1
                \end{bmatrix} \\
                P(z_3 | x_3) &= \begin{bmatrix}
                    0.6 \\
                    0.3 \\
                    0
                \end{bmatrix} \\
                \sum_{x_4} P(x_4 | x_3) P(z_4 | x_4) &= \begin{bmatrix} 0 \\ 0.2 \\ 0.2 \end{bmatrix} \\
                P(z_3 | x_3) \cdot \sum_{x_4} P(x_4 | x_3) P(z_4 | x_4) &= \begin{bmatrix}
                    0.6 \\
                    0.3 \\
                    0
                \end{bmatrix} \cdot \begin{bmatrix} 0 \\ 0.2 \\ 0.2 \end{bmatrix} \\ &= \begin{bmatrix} 0 \\ 0.06 \\ 0 \end{bmatrix} \\
                \sum_{x_3} P(x_3 | x_2) \cdot \begin{bmatrix} 0 \\ 0.06 \\ 0 \end{bmatrix} &= \begin{bmatrix} 0.012 \\ 0.024 \\ 0.036 \end{bmatrix} \\   
                P(x_{2} | x_1) \cdot P(z_{2} | x_2) \cdot \begin{bmatrix} 0.012 \\ 0.024 \\ 0.036 \end{bmatrix} &= \begin{bmatrix} 0.8 \\ 0.2 \\ 0 \end{bmatrix} \cdot \begin{bmatrix} 0.6 \\ 0.3 \\ 0 \end{bmatrix} \cdot \begin{bmatrix} 0.012 \\ 0.024 \\ 0.036 \end{bmatrix} &= \begin{bmatrix} 0.00576 \\ 0.00144 \\ 0 \end{bmatrix} \\
            \end{align*}

            \begin{align*} 
                \intertext{Normalizing the matrix to get the accurate probability we get;} 
                \begin{bmatrix} 0.8 \\ 0.2 \\ 0 \end{bmatrix}               
            \end{align*}
            
            \textbf{Day 3 $\mid$ where data from future days is also available}
            \begin{align*}
                P(x_3 | x_1, z_{2:4}) &= \eta P(x_3 | x_1, z_{2:3})P(z_4 | x_3, x_1, z_{2:3}) \\
                &= \eta P(x_3 | x_2, z_3)P(z_4 | x_3) \\
                &= \eta \begin{bmatrix}
                0.8395 \\
                0.1605 \\
                0
                \end{bmatrix} \cdot \begin{bmatrix}
                0 \\
                0.2 \\
                0
                \end{bmatrix} \\
                &= \begin{bmatrix}
                0 \\
                1 \\
                0
                \end{bmatrix}
            \end{align*}

            \textbf{Day 4 $\mid$ where data from future days is also available}
            \begin{align*}
                P(x_4 | x_1, x_2;x_4) &= P(x_4 | x_3, x_4) \\
                P(x_4 | x_1, x_2;x_4) &= \eta P(z_4 | x_4)P(x_4 | x_3) \\
                P(x_4 | x_1, x_2;x_4) &= \begin{bmatrix}
                0 \\
                0 \\
                1
                \end{bmatrix}
            \end{align*}
            Since we have no future days after Day 4, the probability will remain the same for Day 4. 
        \end{solution}                 
            
        \part Consider the same situation. What is the most likely sequence of weather for Days 2 through 4? What is the probability of the most likely sequence?

        \begin{solution}
            The probability of the sequence of weather is given by
            \begin{align*}
            P(z_{2:4}|x_1, z_{2:4}) &= \eta P(z_{2:4}|x_1, z_{2:4})P(x_{2:4}|x_1) \\
            \intertext{where}
            P(z_{2:4}|x_1) &= P(z_4|x_3)P(z_3|x_2)P(z_2|x_1) \\
            \intertext{and}
            P(x_{2:4}|x_1, z_{2:4}) &= P(z_4|x_4)P(z_3|x_3)P(z_2|x_2)
            \end{align*}

            Hence, the most likely sequence of weather is \textit{sunny, cloudy, rainy} which has \(0.00576\cdot\dfrac{1}{0.00576+0.00144} = 80\%\) of occurring. There is a \(20\%\) probability of \textit{cloudy, cloudy, rainy} and \(0\%\) probability for all other sequences of weather.
        \end{solution}
    \end{parts}

    \question[20]
    \begin{parts}
        \part Complete the incrementalLocalization and all of its subsidiary functions.
        \begin{solution}
        \end{solution}

        \part Comment on the performance of the EKF-based localization after running the simulation for a longer time.
        \begin{solution}
        \end{solution}

        \part Provide an explanation with reference to code on how the measurement uncertainty covariance matrix R is computed from the uncertainty of the lidar.
        \begin{solution}
        \end{solution}

        \part (Bonus) Apply the Unscented Kalman Filter to this problem.
        \begin{solution}
        \end{solution}
    \end{parts}

    \question[20]
    Answer the following questions individually:
    \begin{parts}
        \part How many hours did each of you spend on this homework?
        \begin{solution}
            
        \end{solution}

        \part State each group member's specific contribution to this homework assignment.
        \begin{solution}
        \end{solution}

        \part Do you have any specific advice for students attempting this homework next year?
        \begin{solution}
        \end{solution}

        \part Provide a self-reflection in the form of a note or a concept map.
        \begin{solution}
        \end{solution}
    \end{parts}
\end{questions}

\end{document}